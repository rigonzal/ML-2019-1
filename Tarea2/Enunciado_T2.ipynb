{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Enunciado_T2.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mvmfRzaGg6SV","colab_type":"text"},"source":["<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n","\n","\n","<hr style=\"height:2px;border:none\"/>\n","<h1 align='center'> INF-393/578 Máquinas de Aprendizaje - 2019-1 </h1>\n","\n","<H3 align='center'> Tarea 2  </H3>\n","<hr style=\"height:2px;border:none\"/>\n","\n","**Temas**  \n","* Manipulaciones básicas en numpy\n","* Preprocesamiento y exploración de datos, creación de datos sinteticos\n","* Regresión Lineal Regularizada: _Ridge_ y _Lasso_\n","* SVM y Kernels\n","* Más _Cross Validation_\n","\n","\n","**Formalidades**  \n","* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n","* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos). Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n","* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n","* Formato de entrega: envı́o de link del repositorio en _Github_ (en caso de ser repositorio privado, invitar como colaborador al usuario de github \"avalderr\") al correo electrónico del ayudante (*<alvaro.valderrama.13@sansano.usm.cl>*), en copia al profesor (*<cvalle@inf.utfsm.cl>*). Especificar el siguiente asunto: [INF393/578-2019 Tarea2]\n","* Fecha de entrega y presentaciones: 31 de Mayo. Hora límite de entrega: 23:00. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail. \n","\n","<hr style=\"height:2px;border:none\"/>\n","\n","La tarea se divide en dos partes:\n","\n","[1.](#primero) Clasificación de datos no-linealmente separables  \n","[2.](#tercero) Regularización para regresión   \n","\n","La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo solo son guias y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n","Recuerden intercalar su código con comentarios y con celdas _Markdown_ con los comentarios de la pregunta y con cualquier analisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. \n","Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará mucho la elección en si, en cambio la argumentación detrás de la elección será lo más ponderado.\n","Si algun modelo se demora demasiado en correr en su maquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, esto puede ser relevante para las maquinas más lentas al momento de realizar exploraciones con _K-folds_ por ejemplo."]},{"cell_type":"markdown","metadata":{"id":"IC4_8Ai9g6SW","colab_type":"text"},"source":["<a id=\"primero\"></a>\n","## 1. Clasificación de datos no-linealmente separables\n","\n","Algunos modelos de clasificación buscan implicita o explicitamente separar los datos linealmente, es decir ajustar un hiperplano que separe en 2 subespacios el espacio de las variables, separando ambas clases del _target_. Sin embargo en la mayoría de los casos reales esto resulta imposible. Esto no significa que no podamos ajustar modelos con estos datos o buscar transformaciones que nos permitan utilizarlos. \n","    \n","![Alt Text](http://people.cs.uchicago.edu/~dinoj/manifold/swissroll.gif) \n","\n","[comment]: <> (Swiss Roll)\n","\n","En esta primera parte de la tarea crearemos manualmente un set de datos categóricos no linealmente separables. Este se conformará de puntos en $\\mathbb{R}^2$, pertenecientes a una de dos categorías etiquetadas 0 o 1, los cuales se encuentran \"anidados\". Probaremos distintas aproximaciones lineales y no lineales y compararemos sus desempeños.\n"]},{"cell_type":"markdown","metadata":{"id":"BMH1iax1g6SX","colab_type":"text"},"source":["#### 1.a Creando los datos\n","La función `do_circles` retorna un conjunto de puntos etiquetados, donde la etiqueta 0 corresponde a puntos siguiendo una circunferencia (con un ruido asociado) y la etiqueta 1 a puntos dentro de esa circunferencia.\n","\n","Los parametros de esta función tienen nombres intencionalmente no descriptivos. Analise la función y comente interpretación puede darle a cada uno de los parámetros con respecto a la influencia que tendrán en el set de datos obtenidos. Si lo estima conveniente, cambie el nombre de los parámetros a nombres más descriptivos."]},{"cell_type":"code","metadata":{"id":"mPYpebdYg6SY","colab_type":"code","colab":{}},"source":["def do_circles(n_dots = 3000, ns = 0.15, scr = 0.3, cf = 1):\n","    generator = check_random_state(42)\n","    \n","    linspace = np.linspace(0, 2*cf*np.pi, n_dots)\n","    circle_x = np.cos(linspace)\n","    circle_y = np.sin(linspace)\n","\n","    inner_circle_x, outer_circle_x, inner_circle_y, outer_circle_y = train_test_split(circle_x, circle_y, test_size = 0.5)\n","    inner_circle_x , inner_circle_y = inner_circle_x*scr , inner_circle_y*scr \n","\n","    X = np.vstack((\n","        np.append(outer_circle_x, inner_circle_x),\n","        np.append(outer_circle_y, inner_circle_y)\n","    )).T\n","\n","    y = np.hstack([\n","        np.zeros(n_dots // 2, dtype=np.intp),\n","        np.ones(n_dots // 2, dtype=np.intp)\n","    ])\n","\n","    X += generator.normal(scale = ns, size = X.shape)\n","    return train_test_split(X, y, test_size=0.3, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nicM5qx_g6Sc","colab_type":"text"},"source":["#### 1.b Graficar los datos\n","Cree una función que grafíque los datos, coloreando distintamente los puntos de cada clase. \n","Utilice esta función para verificar gráficamente lo que propuso en la pregunta anterior."]},{"cell_type":"code","metadata":{"id":"t-Wv4R5ug6Sd","colab_type":"code","colab":{}},"source":["def plot_circles( . . . . ):\n","    # . . . \n","    fig1 = fig.add_subplot(121)\n","    fig1.scatter(X_train[y_train==0][:,0], X_train[y_train==0][:,1])\n","    # . . . \n","    fig1.set_title(\"Train Set\")\n","    # . . ."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Si5zi60Lg6Sh","colab_type":"text"},"source":["#### 1.c Regresión Logística\n","\n","Realice una regresión logistica para a lo menos 5000 puntos generados con los siguientes parámetros:\n","* `do_circles(n_dots, 0.2, 0.3, 1)`\n","* `do_circles(n_dots, 0, 0.3, 1)`\n","\n","Grafique los datos que está ajustando y calcule el _score_ del regresor logístico en cada caso.\n","¿Qué valor entrega el _score_ del regresor logístico? ¿Le parece un buen desempeño para la tarea a realizar?"]},{"cell_type":"code","metadata":{"id":"-a-9gN34g6Si","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","# . . ."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6uO0J1Pbg6Sl","colab_type":"text"},"source":["#### 1.d Graficos\n","Para entender mejor lo que está ocurriendo con el clasificador en cada uno de los casos, grafícaremos los datos clasificados y la frontera de desición ajustada por el modelo. Para esto complete la función siguiente y luego utilicela para ambos modelos y conjuntos de datos ajustados en la pregunta anterior. \n","\n","¿Qué puede concluir luego de estas visualizaciones? ¿Es posible mejorar el desempeño de algun clasificador lineal sin hacer una transformación de los datos? ¿Qué ocurre con el clasificador si disminuimos el ruido, mejora realmente su desempeño? "]},{"cell_type":"code","metadata":{"id":"8w2cO3DNg6Sm","colab_type":"code","colab":{}},"source":["def plot_classifier(classifier, X_train, Y_train, X_test, Y_test, train_or_test='test'):\n","    plt.figure(figsize=(12, 8))\n","    axis = plt.axes()\n","    if tr_tst == 'train':\n","        # Scatter train points (axis.scatter(. . .)) \n","    elif tr_tst == 'test':\n","        # Scatter test points\n","    XX, YY = np.mgrid[-2:2:200j, -2:2:200j] # grid for cassifier\n","    Z = clf.predict(np.c_[XX.ravel(), YY.ravel()]) # what the classifier predicts over the space\n","    Z = Z.reshape(XX.shape) # for consistency\n","    Zplot = Z > 0.5 # to separate both classes\n","    axis.pcolormesh(XX, YY, Zplot, cmap='YlGn')\n","    axis.contour(XX, YY, Zplot, alpha=1, colors=[\"r\"], linestyles=[\"-\"], levels=[0.5])\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8rlux2Yg6Sp","colab_type":"text"},"source":["Para las siguientes preguntas nos enfocaremos **solo en la versión con ruido de los datos** pues en la práctica no existen datos sin ruido. Probaremos algunos métodos no lineales para ver que tanto logramos mejorar el desempeño en nuestros datos. "]},{"cell_type":"markdown","metadata":{"id":"_gdVMuYNg6Sq","colab_type":"text"},"source":["#### 1.e SVM\n","\n","Entrene un clasificador SVM con los datos con ruido. ¿Qué forma tiene la frontera de desición esta vez? \n","\n","¿Mejoran los resultados al alejarse de los metodos puramente lineales? Comente sobre el desempeño del modelo y su sensibilidad a los parámetros `C` y `gamma`, explorando como cambia la frontera de desición al variar estos parámetros. "]},{"cell_type":"code","metadata":{"id":"oHPHqSJXg6Sr","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC\n","SV = SVC(C=1, gamma=5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9av907g-g6Su","colab_type":"text"},"source":["#### 1.f KNN\n","Pruebe ahora con otro método no linal, _K nearest neighbors_ o KNN. Discuta sus resultados y la frontera de desición que encuentra el modelo. \n","\n","Realice un _Cross Validation_ sobre el parámetro `n_neighbors` o `p` (o ambos usando un mallado) y comente si mejoran significativamente los resultados. Puede apoyarse de los códigos de la tarea 1 para realizar el _Cross Validation_.\n","¿Qué representan estos parámetros para el metodo?"]},{"cell_type":"code","metadata":{"id":"GFGfrLXqg6Sv","colab_type":"code","colab":{}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","KNN = KNeighborsClassifier(n_neighbors=5, p=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-W5ysefg6Sy","colab_type":"text"},"source":["#### 1.g\n","Del mejor modelo obtenido en el punto anterior, grafíque los datos de test coloreando de manera difente los puntos mal clasificados por su modelo. ¿Por qué el modelo no logra clasificar bien estos puntos? ¿Qué habría ocurrido si estuvieramos utilizando los datos sin ruido?"]},{"cell_type":"code","metadata":{"id":"IqdEKQjXg6Sz","colab_type":"code","colab":{}},"source":["# do it yourself c:"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXyW3k0Sg6S3","colab_type":"text"},"source":["#### 1.h Metodo Kernel\n","Utilizaremos Kernel Gaussiano para preprocesar los datos, pasando implícitamente por un espacio altamente dimensional (más especificamente por un _manifold_ de un espacio infinito dimensional), obteniendo una representación lo más linealmente separable posible. \n","\n","Ajuste el kernel y transforme los datos. Grafique los puntos transformados y comente que realiza el modelo. Varie luego el valor de `gamma` para tratar de entender qué influencia tiene sobre la separabilidad de los puntos transformados. ¿Le parece un buen método para este problema? \n","\n","Usando algún valor de `gamma` que le parezca adecuado, ajuste un modelo de regresión logística sobre los datos transformados. Mejora el desempeño del modelo respecto a la versión original? ¿Se logra aumentar la separabilidad lineal de los datos efectivamente? Apoyese de gráficos y métricas adecuados. "]},{"cell_type":"code","metadata":{"id":"qebCEiuTg6S4","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import KernelPCA\n","ker = KernelPCA(2,kernel='rbf',gamma=5)\n","ker.fit(X_train)\n","X_ker_train = ker.transform(X_train)\n","# . . "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ffgzP_64g6S6","colab_type":"text"},"source":["#### 1.i Manualmente\n","Como nosotros conocemos como se generaron los datos tenemos una ventaja sobre los modelos. Genere una transformación de los datos que estime conveniente para obtener datos linealmente separables. Puede aumentar o disminuir la dimensión a gusto, por ejemplo puede realizar algo del estilo $(x,y)\\longrightarrow (x+y)$, ó $(x,y)\\longrightarrow (x,y,x+y,x-y)$. Apoyese de las carácteristicas geométricas del conjunto de datos y justifique sus elecciónes con gráficos adecuados. \n","\n","Luego entrene un regresor logístico sobre sus datos transformados y comente sobre la utilidad de conocer cómo se generaron los datos. Grafíque los datos transformados o alguna proyección de ellos junto con la frontera de desición y comente sobre lo que realiza su transformación."]},{"cell_type":"markdown","metadata":{"id":"LLaW83QPg6S7","colab_type":"text"},"source":["<a id=\"tercero\"></a>\n","## 2. Regularización para regresión. \n","\n","Un problema que podemos encontrar transversalmente a todos los modelos es el problema del _overfitting_. Este problema consiste en un modelo que aprende demasiado bien los datos de ejemplo o entrenamiento, al punto que al momento de ver ejemplos desconocidos o de validación, baja su desempeño respecto a un modelo \"menos entrenado\". En algunos casos podriamos decir que el modelo \"aprende de memoria\" los ejemplos, en vez de intentar obtener información generalizable a partir de su entrenamiento. Para el caso de la regresión, una de las aproximaciones más comunes para tratar de mitigar este efecto es el de la regularización. Agregando una penalización a la norma de los parametros de la regresión podemos restringir la eficiencia del modelo al momento de aprender los datos de entrenamiento, incluso forzando dependiendo de la intensidad de la regularización que algunos parametros se vuelvan cero. \n","\n","<img src=\"https://pngimage.net/wp-content/uploads/2018/06/house-for-sale-sign-png-6.png\"  style=\"height:13.9cm;\"  />\n","\n","En esta pregunta utilizaremos nuevamente la base de datos de precios de casas en King County, https://www.kaggle.com/harlfoxem/housesalesprediction, que utilizamos en la Tarea 1. Utilizaremos estos datos ya conocidos y analizados anteriormente para enfocarnos en la regularización para regresión. Exploraremos como varian los distintos errores de predicción y como cambian los valores de los parámetros ajustados por el modelo para distintos valores del coeficiente de regularización, para tratar de entender que ocurre con las distintas regularizaciones y sus diferencias. "]},{"cell_type":"markdown","metadata":{"id":"N9QOT-9Eg6S8","colab_type":"text"},"source":["#### 2.a Carga y preprocesamiento.\n","Cargue y preprocese los datos de la misma forma en que lo realizó en la tarea 1, incluyendo estandarizar el _target_. Puede reciclar sus códigos y agregar modificaciones que le parezcan pertinentes.  Para esta parte utilize 0.5 de los datos como _training set_, 0.3 como _validation set_ y 0.2 como _test set_."]},{"cell_type":"markdown","metadata":{"id":"cYHkjRXqg6S9","colab_type":"text"},"source":["#### 2.b Modelo sin regularización\n","Entrene un modelo de regresión lineal no regularizado con los datos preprocesados. Calcule el error cuadrático medio (MSE) del modelo para el conjunto de validación y el de entrenamiento. "]},{"cell_type":"code","metadata":{"id":"HMP-wBEHg6S9","colab_type":"code","colab":{}},"source":["regressor = LinearRegression()\n","regressor.fit(# . . . )\n","    \n","mse = ((reg.predict(x_val)-y_val)**2).mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tj5bSk8eg6TA","colab_type":"text"},"source":["#### 2.c Regularización\n","Discuta que busca realizar (en términos del ajuste de los parámetros del modelo de regresión lineal) la regularización de _Lasso_. ¿Por qué se habla de penalización en norma $L^1$? Apóyese de ecuaciones. ¿Qué importancia tiene el parámetro de regularización $\\lambda$? \n","\n","¿Qué diferencia hay entre _Lasso_ y _Ridge_? "]},{"cell_type":"markdown","metadata":{"id":"19P-PgMfg6TB","colab_type":"text"},"source":["#### 2.d Influencia sobre el error\n","Grafique como varia el error de entrenamiento y el error de validación a medida se cambia el valor del parámetro $\\lambda$. Para esto debe entrenar un modelo para cada uno de los parámetros que considerará en el gráfico y calcular el MSE para ambos sets. Comente sobre lo que ve en el gráfico y si lo encuentra pertinente puede calcular en más detalle alguna zona que le parezca interesante. \n","Es conveniente entrenar primero unos cuantos modelos con valores de $\\lambda$ escogidos manualmente para saber mejor en que intervalo resulta pertinente calcular estos valores (para _Ridge_ se necesitan valores más altos en este caso para ver la influencia sobre el error).\n","\n","Note que el parámetro $\\lambda$ es sensible a la escala de los datos, por lo cual deberá estudiar valores distintos dependiendo de si estandarizó el _target_ o no. "]},{"cell_type":"code","metadata":{"id":"BiL_5_kIg6TB","colab_type":"code","colab":{}},"source":["# for example:\n","MSE_list = []\n","space = pd.np.logspace(-2,1,100)\n","for lambd in space:\n","    model = Lasso(alpha=lambd)\n","    # fit, error...\n","# . . . \n","# plt.plot( space, MSE_list, . . . ) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4T29bAP2g6TE","colab_type":"text"},"source":["#### 2.e Influencia sobre los coeficientes\n","Grafique ahora como se comporta el valor de los coeficientes del modelo lineal en el modelo entrenado a medida crece $\\lambda$, tanto para _Lasso_ como para _Ridge_. Para esto entrene un modelo para cada valor de $\\lambda$ y guarde sus coeficientes, como propone el princio de código a continuación. Debe explorar valores de $\\lambda$ donde todos los coeficientes sean no nulos hasta valores donde todos los coeficientes se anulan. \n","\n","¿Qué diferencias ve entre _Ridge_ y _Lasso_? ¿Coincide este comportamiento con lo que esperaría teóricamente de cada uno de los modelos? \n","\n","¿Podemos utilizar estos gráficos para discutir sobre la cantidad de información que entrega cada uno de los atributos para predecir el _target_? ¿Cual de ambos (_Ridge_ o _Lasso_) le parece mejor para este tipo de discución? Compare lo que muestran estos gráficos con alguna otra aproximación para medir la significancia de cada atributo (como correlación o _mutual information_ por ejemplo) y discuta. "]},{"cell_type":"code","metadata":{"id":"TxH2Lyuwg6TF","colab_type":"code","colab":{}},"source":["space = pd.np.linspace(0.0001,3,100) \n","# should be fine for Lasso, for Ridge try space = pd.np.logspace(0,10,50) and plot x on a logarithmic\n","# scale (you can simply do np.linspace(0,10,50) when setting x values for the plot)\n","coefs = []\n","for l in space:\n","    model = # . . .\n","    \n","    # . . .\n","    \n","    coefs.append(model.coef_)\n","\n","for y_arr, label in zip(pd.np.squeeze(coefs).T, x_cols):\n","    plt.plot(space, y_arr, label=label)\n","    # . . ."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"00xhF-k_g6TH","colab_type":"text"},"source":["#### 2.f K-_fold_ sobre $\\lambda$\n","Realice 5-_fold_ o 10-_fold_ sobre el parámetro de regularización $\\lambda$, ya sea para _Lasso_ o _Ridge_. Explore a lo menos 20 valores distintos de $\\lambda$ en un intervalo relevante luego de lo aprendido en las preguntas anteriores. Utilice MSE como el error a minimizar. \n","\n","Compare el error de entrenamiento y de validación para este modelo respecto al modelo lineal sin regularización entrenado inicialmente. ¿En su opinión se alcanza a apreciar el fenomeno de _overfitting_ para este conjunto de datos y el modelo logístico? "]},{"cell_type":"markdown","metadata":{"id":"I22j4BEeg6TI","colab_type":"text"},"source":["#### 2.g _Grid search_ para SVM\n","\n","Para terminar, comparemos el desempeño de los métodos lineales con un método no lineal, las SVM. Para esto buscaremos ajustar los hiperparámetros más relevantes del modelo, en este caso el parámetro `C` y `epsilon`, la penalización y el margen de holgura. Comente sobre la significancia de estos parámetros y su influencia sobre la máquina. Luego realice una busqueda en un mallado de estos parámetros, evaluando el _score_ (coeficiente de determinación) o MSE o ambos.\n","\n","*Nota*: Entrenar una SVM toma mucho más tiempo que las regresiones lineales, por lo cual es recomendable probar primero su código en un número reducido de puntos y luego entrenar todos los modelos asegurandose de guardar bien los resultados. Si su maquina es muy lenta es incluso recomendable que esta parte la realice en _Collab_ de Google si desea explorar un número relevante de puntos. El mallado propuesto en el código es de referencia y puede elegirlo o construirlo como usted estime más conveniente. \n","\n","De todos los modelos entrenados, ¿Cuál es el mejor? ¿Cómo se compara el desempeño de este modelo con el mejor modelo lineal encontrado por usted? Adjunte gráficos que le parezcan relevantes. "]},{"cell_type":"code","metadata":{"id":"ABBxGu3Dg6TJ","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVR\n","\n","Cs, epsilons = pd.np.meshgrid([i for i in range(1,10)],[i/20 for i in range(1,21)])\n","for for C, epsilon in zip(Cs.reshape((-1,1)), epsilons.reshape((-1,1))):\n","    sv = SVR(C=C, epsilon=epsilon)\n","    \n","    # fit and save the scores for each one"],"execution_count":0,"outputs":[]}]}