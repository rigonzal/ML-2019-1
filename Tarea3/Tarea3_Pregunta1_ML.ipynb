{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea3-Pregunta1-ML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rigonzal/ML-2019-1/blob/master/Tarea3/Tarea3_Pregunta1_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5r6GjrCp_n-",
        "colab_type": "text"
      },
      "source": [
        "# INF-393: Máquinas de Aprendizaje\n",
        "\n",
        "## Tarea 3 - Pregunta 1\n",
        "\n",
        "13-09-2019\n",
        "\n",
        "\n",
        "\n",
        "*   Rodrigo González Smith           -- 201303026-2\n",
        "*   Ignacio Valenzuela Albornoz   -- 201473055-1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGhdxNJlDkFr",
        "colab_type": "text"
      },
      "source": [
        "## Regresión para ubicación espacial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9atB3QhDIXs",
        "colab_type": "code",
        "outputId": "add22768-0560-491e-cff0-5988f9144700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM2MqL_SG8xE",
        "colab_type": "text"
      },
      "source": [
        "## a) Carga de datos\n",
        "\n",
        "En esta ocasión, realizaremos un análisis en un dataset bien particular. El problema en cuestión tiene relación con la ubicación espacial de ciertos dispositivos en lugares cerrados, principalmente en edificaciones. En espacios exteriores tenemos la señal GPS con la que nuestros celulares y otros dispositivos detectan nuestra ubicación, pero en interiores el material de las estructuras reducen o incluso reflectan estas señales, por lo que se han buscado diversos métodos o técnicas para poder modelar la ubicación espacial sin la ayuda del GPS.\n",
        "\n",
        "El dataset es de la Universidad de Jaume, el cual se hicieron 20000 mediciones en 3 estructuras de esta universidad. Primero que todo, cargaremos los datos desde la nube en google drive e imprimimos las primeras 5 filas para identificar la composición del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fBaVaVSGWVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = pd.read_csv(\"/content/drive/My Drive/trainingData.csv\")\n",
        "validation = pd.read_csv(\"/content/drive/My Drive/validationData.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd0ifXW_IXB9",
        "colab_type": "code",
        "outputId": "61973769-e393-4849-bddc-919dbf19c2a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "training[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WAP001</th>\n",
              "      <th>WAP002</th>\n",
              "      <th>WAP003</th>\n",
              "      <th>WAP004</th>\n",
              "      <th>WAP005</th>\n",
              "      <th>WAP006</th>\n",
              "      <th>WAP007</th>\n",
              "      <th>WAP008</th>\n",
              "      <th>WAP009</th>\n",
              "      <th>WAP010</th>\n",
              "      <th>WAP011</th>\n",
              "      <th>WAP012</th>\n",
              "      <th>WAP013</th>\n",
              "      <th>WAP014</th>\n",
              "      <th>WAP015</th>\n",
              "      <th>WAP016</th>\n",
              "      <th>WAP017</th>\n",
              "      <th>WAP018</th>\n",
              "      <th>WAP019</th>\n",
              "      <th>WAP020</th>\n",
              "      <th>WAP021</th>\n",
              "      <th>WAP022</th>\n",
              "      <th>WAP023</th>\n",
              "      <th>WAP024</th>\n",
              "      <th>WAP025</th>\n",
              "      <th>WAP026</th>\n",
              "      <th>WAP027</th>\n",
              "      <th>WAP028</th>\n",
              "      <th>WAP029</th>\n",
              "      <th>WAP030</th>\n",
              "      <th>WAP031</th>\n",
              "      <th>WAP032</th>\n",
              "      <th>WAP033</th>\n",
              "      <th>WAP034</th>\n",
              "      <th>WAP035</th>\n",
              "      <th>WAP036</th>\n",
              "      <th>WAP037</th>\n",
              "      <th>WAP038</th>\n",
              "      <th>WAP039</th>\n",
              "      <th>WAP040</th>\n",
              "      <th>...</th>\n",
              "      <th>WAP490</th>\n",
              "      <th>WAP491</th>\n",
              "      <th>WAP492</th>\n",
              "      <th>WAP493</th>\n",
              "      <th>WAP494</th>\n",
              "      <th>WAP495</th>\n",
              "      <th>WAP496</th>\n",
              "      <th>WAP497</th>\n",
              "      <th>WAP498</th>\n",
              "      <th>WAP499</th>\n",
              "      <th>WAP500</th>\n",
              "      <th>WAP501</th>\n",
              "      <th>WAP502</th>\n",
              "      <th>WAP503</th>\n",
              "      <th>WAP504</th>\n",
              "      <th>WAP505</th>\n",
              "      <th>WAP506</th>\n",
              "      <th>WAP507</th>\n",
              "      <th>WAP508</th>\n",
              "      <th>WAP509</th>\n",
              "      <th>WAP510</th>\n",
              "      <th>WAP511</th>\n",
              "      <th>WAP512</th>\n",
              "      <th>WAP513</th>\n",
              "      <th>WAP514</th>\n",
              "      <th>WAP515</th>\n",
              "      <th>WAP516</th>\n",
              "      <th>WAP517</th>\n",
              "      <th>WAP518</th>\n",
              "      <th>WAP519</th>\n",
              "      <th>WAP520</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>FLOOR</th>\n",
              "      <th>BUILDINGID</th>\n",
              "      <th>SPACEID</th>\n",
              "      <th>RELATIVEPOSITION</th>\n",
              "      <th>USERID</th>\n",
              "      <th>PHONEID</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-7541.2643</td>\n",
              "      <td>4.864921e+06</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1371713733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-7536.6212</td>\n",
              "      <td>4.864934e+06</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1371713691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-97</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-7519.1524</td>\n",
              "      <td>4.864950e+06</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1371714095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-92</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-7524.5704</td>\n",
              "      <td>4.864934e+06</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1371713807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-7632.1436</td>\n",
              "      <td>4.864982e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>1369909710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 529 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   WAP001  WAP002  WAP003  ...  USERID  PHONEID   TIMESTAMP\n",
              "0     100     100     100  ...       2       23  1371713733\n",
              "1     100     100     100  ...       2       23  1371713691\n",
              "2     100     100     100  ...       2       23  1371714095\n",
              "3     100     100     100  ...       2       23  1371713807\n",
              "4     100     100     100  ...      11       13  1369909710\n",
              "\n",
              "[5 rows x 529 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_dZS08hIx0x",
        "colab_type": "text"
      },
      "source": [
        "Podemos apreciar que posee una cantidad de atributos inmensa donde la mayoría no parece darnos información muy explícita, excepto las últimas columnas que tienen nombres más intuitivos. Aún así, revisaremos la documentación del dataset para conocer mejor qué significa cada atributo en cuestión.\n",
        "\n",
        "\n",
        "\n",
        "*   WAP: Este atributo se repite unas 520 veces. WAP significa \"Wi-Fi Access Point\", que representa los puntos de acceso a WiFi que posee la Universidad. El valor de cada WAP representa la intensidad que esta posee, con valores enteros en un rango de -104 a 0. También puede tomar el valor de 100 que indica que no se detectó, en esa medición, el punto de acceso WAPxxx.\n",
        "*   Longitude: Es la longitud de donde se realizó la medición. Toma valores negativos entre -7695.9387549299299000 to -7299.786516730871000.\n",
        "*   Latitude: La latitud de donde se realizó la medición. Toma valores positivos entre 4864745.7450159714 to 4865017.3646842018\n",
        "*   Floor: Un valor entero entre 0 y 4, que indica el piso donde se hizo la medición. También se puede considerar como la altitud de la medición\n",
        "*   BuildingID: Las mediciones se realizaron en 3 edificios diferentes de la universidad, por lo tanto se representa en la medición en valores enteros de 0, 1 y 2.\n",
        "*   SpaceID: Un identificador es específica en que tipo de espacio se realizó la medición. 0 para una oficina, 1 para un pasillo y 2 para una sala de clases.\n",
        "*   RelativePosition: Refleja la posición relativa de la posición. Posee un valor booleano, donde 0 implica que se está dentro (de la oficina o sala de clases por ejemplo) y 1 que se encuentra fuera de esta pero en frente de la puerta de entrada.\n",
        "*   UserID: Es el identificador del usuario que realizó la medición. Es un valor categórico, por lo que su representación se puede ver a continuación:\n",
        " \n",
        "\n",
        "      0 USER0000 (Validation User) N/A\n",
        "      1 USER0001 170\n",
        "      2 USER0002 176\n",
        "      3 USER0003 172\n",
        "      4 USER0004 174\n",
        "      5 USER0005 184\n",
        "      6 USER0006 180\n",
        "      7 USER0007 160\n",
        "      8 USER0008 176\n",
        "      9 USER0009 177\n",
        "      10 USER0010 186\n",
        "      11 USER0011 176\n",
        "      12 USER0012 158\n",
        "      13 USER0013 174\n",
        "      14 USER0014 173\n",
        "      15 USER0015 174\n",
        "      16 USER0016 171\n",
        "      17 USER0017 166\n",
        "      18 USER0018 162 \n",
        "\n",
        "*   PhoneID: Es el identificador del celular que se utilizó para la medición. También es categórico y representa principalmente el modelo de celular y su versión de android. Las representaciones son como siguen:\n",
        "\n",
        "      0 Celkon A27 4.0.4(6577) 0\n",
        "      \n",
        "      1 GT-I8160 2.3.6 8\n",
        "      \n",
        "      2 GT-I8160 4.1.2 0\n",
        "      \n",
        "      3 GT-I9100 4.0.4 5\n",
        "      \n",
        "      4 GT-I9300 4.1.2 0\n",
        "      \n",
        "      5 GT-I9505 4.2.2 0\n",
        "      \n",
        "      6 GT-S5360 2.3.6 7\n",
        "      \n",
        "      7 GT-S6500 2.3.6 14\n",
        "      \n",
        "      8 Galaxy Nexus 4.2.2 10\n",
        "      \n",
        "      9 Galaxy Nexus 4.3 0\n",
        "      \n",
        "      10 HTC Desire HD 2.3.5 18\n",
        "      \n",
        "      11 HTC One 4.1.2 15\n",
        "      \n",
        "      12 HTC One 4.2.2 0\n",
        "      \n",
        "      13 HTC Wildfire S 2.3.5 0,11\n",
        "      \n",
        "      14 LT22i 4.0.4 0,1,9,16\n",
        "      \n",
        "      15 LT22i 4.1.2 0\n",
        "      \n",
        "      16 LT26i 4.0.4 3\n",
        "      \n",
        "      17 M1005D 4.0.4 13\n",
        "      \n",
        "      18 MT11i 2.3.4 4\n",
        "      \n",
        "      19 Nexus 4 4.2.2 6\n",
        "      \n",
        "      20 Nexus 4 4.3 0\n",
        "      \n",
        "      21 Nexus S 4.1.2 0\n",
        "      \n",
        "      22 Orange Monte Carlo 2.3.5 17\n",
        "      \n",
        "      23 Transformer TF101 4.0.3 2\n",
        "      \n",
        "      24 bq Curie 4.1.1 12 \n",
        "\n",
        "\n",
        "*   TimeStamp: Representa la hora, en formato timestamp, en la cual fue realizada la medición.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5eyRQhizDhI",
        "colab_type": "text"
      },
      "source": [
        "Por el momento, combinaremos ambos archivos en un solo dataframe para poder manejar más a nuestro antojo la división entre conjuntos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64UgCQavIpTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = training.append(validation, ignore_index = True).sample(frac = 1).reset_index().drop(\"index\", axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2WllBuGzo_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets = np.array([520,521,522])\n",
        "attributes = np.arange(0, len(df.columns))\n",
        "target_col =  df.columns[targets]  # Obtenemos las columnas que representarán el target\n",
        "attribute_col = df.columns[np.setdiff1d(attributes, targets)] # Rescatamos las columnas que no son target\n",
        "x_un = pd.get_dummies(df.PHONEID) # Categorizamos el atributo phoneid\n",
        "categorical_columns = x_un.columns # Almacenamos el nombre de los nuevos atributos dummy\n",
        "x_un[attribute_col] = df[attribute_col] # Finalmente agregamos las demás columnas que nos ayudan en el target\n",
        "y_u = df[target_col] #Finalmente tenemos otro dataframe con los targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIiQEPJA9X8l",
        "colab_type": "text"
      },
      "source": [
        "Ya tenemos el dataset preparado, y ahora debemos volver a dividirlo en training y validation. Debido a que el dataset ya fue aleatoriamente ordenado, podemos dividirlo respecto a sus índices solamente (en vez de usar train_test_split, por ejemplo). Una de las incidencias que podría ocurrir al no hacer shuffle es que las mediciones se hayan hecho y almacenado de forma consecutiva, por lo que habría un factor de tiempo involucrado, por lo que muchas filas juntas pueden tener valores de latitud y longitud más cercanas, en cambio si realizamos un shuffle rompemos esa relación, teniendo así solos los atributos como fuentes de información para definir la latitud o longitud en el cual ze encontraba el dispositivo en el momento de la medición.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY760VgmOsxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr_un = x_un[0:16838]\n",
        "y_tr_un = y_u[0:16838]\n",
        "\n",
        "x_val_un = x_un[16838:]\n",
        "y_val_un = y_u[16838:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vzf-gJqOtXE",
        "colab_type": "text"
      },
      "source": [
        "## b) Estandarizar los datos\n",
        "\n",
        "Ahora se estandarizarán los datos. Debido a que poseemos datos categóricos y no categóricos, se debe aplicar una estandarización distinta. Respecto a los atributos no categóricos, aplicaremos un StandardScaler que estandarizará respecto a la media y desviación estándar de cada atributo. Por otra parte, los atributos categóricos (que son 0 o 1) se les restará 0.5, para que así recorran tanto el espacio de los negativos y los positivos y estén centrados en 0.\n",
        "\n",
        "También debemos estandarizar los targets, que son la latitud, longitud y los pisos. El atributo floor es categórico, pero aún así se considerará como continuo (se le aplicará StandardScaler) para así ver como nuestros modelos pueden aproximar la altitud de las mediciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXn9OZSJ4fv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datos de entrenamiento\n",
        "\n",
        "scaler_x = StandardScaler()\n",
        "scaler_x.fit(x_tr_un[attribute_col])\n",
        "x_tr = pd.np.concatenate((scaler_x.transform(x_tr_un[attribute_col]), x_tr_un[categorical_columns].values-0.5), axis=1)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "scaler_y.fit(y_tr_un)\n",
        "y_tr = pd.DataFrame(scaler_y.transform(y_tr_un))\n",
        "\n",
        "# Datos de validacion\n",
        "\n",
        "scaler_x = StandardScaler()\n",
        "scaler_x.fit(x_val_un[attribute_col])\n",
        "x_val = pd.np.concatenate((scaler_x.transform(x_val_un[attribute_col]), x_val_un[categorical_columns].values-0.5), axis=1)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "scaler_y.fit(y_val_un)\n",
        "y_val = pd.DataFrame(scaler_y.transform(y_val_un))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw4gF-s1pizK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tr_o = []\n",
        "y_val_o = []\n",
        "for index, row in y_tr.iterrows():\n",
        "  y_tr_o.append(np.array(row))\n",
        "for index, row in y_val.iterrows():\n",
        "  y_val_o.append(np.array(row))\n",
        "  \n",
        "y_tr = np.array(y_tr_o)\n",
        "y_val = np.array(y_val_o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooBQB-w3LXBC",
        "colab_type": "text"
      },
      "source": [
        "## c) Primer árbol\n",
        "\n",
        "Comenzaremos con la construcción de un árbol de profundidad 3 y con una función de error MAE (Maximum Absolute Error). Mediremos su desempeño, tiempo de ejecución y comparativas con un modelo de regresión lineal común."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FVe7IH4KZVo",
        "colab_type": "code",
        "outputId": "e3b2d9bf-7d00-496c-8f43-0b27bb3a43d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tree = DecisionTreeRegressor(criterion='mae', max_depth=3)\n",
        "ini = time.time()\n",
        "tree.fit(x_tr, y_tr)\n",
        "fin = time.time()\n",
        "print(fin - ini, \"[s]\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.79273533821106 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWaWCRzmOcvc",
        "colab_type": "text"
      },
      "source": [
        "Vemos que el entrenamiento del árbol de decisión se demoró aproximadamente minuto y medio. Calculemos el score que nos ofrece el árbol en ambos conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ech5ImM7NFPP",
        "colab_type": "code",
        "outputId": "8255a8c0-261e-4a08-852d-1c84d9577096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "score_tr = tree.score(x_tr, y_tr)\n",
        "score_val = tree.score(x_val, y_val)\n",
        "\n",
        "print(\"Training set score: \", score_tr)\n",
        "print(\"Validation set score: \", score_val)\n",
        "\n",
        "predicted_tr = tree.predict(x_tr)\n",
        "predicted_val = tree.predict(x_val)\n",
        "MAE_tr = mean_absolute_error(y_tr, predicted_tr)\n",
        "MAE_val = mean_absolute_error(y_val, predicted_val)\n",
        "\n",
        "print(\"Training set MAE: \", MAE_tr)\n",
        "print(\"validation set MAE: \", MAE_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score:  0.671262329073306\n",
            "Validation set score:  0.6680176057709891\n",
            "Training set MAE:  0.3731321734914379\n",
            "validation set MAE:  0.38143475694074036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WEYtPVsQhaM",
        "colab_type": "text"
      },
      "source": [
        "Podemos apreciar que el score en ambos conjuntos es bastante parecido, un 67% aproximadamente. Vimos que el tiempo de entrenamiento fue mas de lo que acostumbramos en el curso, por lo que comprobemos con una regresión lineal común si podemos obtener un desempeño parecido o mejor con menos tiempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE17jef6OntM",
        "colab_type": "code",
        "outputId": "39016017-ab90-4768-8a38-1e91f06a06bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "ini = time.time()\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x_tr, y_tr)\n",
        "fin = time.time()\n",
        "print(fin - ini, \"[s]\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.09576416015625 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDN__PwUjoLm",
        "colab_type": "code",
        "outputId": "f8adb32b-e763-408a-f16c-1a57a8b59994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Training set score: \", lin_reg.score(x_tr, y_tr))\n",
        "print(\"Validation set score: \", lin_reg.score(x_val, y_val))\n",
        "\n",
        "predicted_tr = lin_reg.predict(x_tr)\n",
        "predicted_val = lin_reg.predict(x_val)\n",
        "\n",
        "print(\"Training set MAE: \", mean_absolute_error(y_tr, predicted_tr))\n",
        "print(\"validation set MAE: \", mean_absolute_error(y_val, predicted_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score:  0.952966279796521\n",
            "Validation set score:  -1.3820883352120975e+22\n",
            "Training set MAE:  0.15228050052354156\n",
            "validation set MAE:  3299119706.884302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YynVt1UOTapS",
        "colab_type": "text"
      },
      "source": [
        "## d) Usando Stump\n",
        "\n",
        "Analizando la profundidad de los árboles, podemos hacer un experimento con profundidad 1. Calcularemos su score y también el MAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsQuL31SSHhF",
        "colab_type": "code",
        "outputId": "20c2b9f0-b8df-4fef-90d6-24a184672807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ini = time.time()\n",
        "stump =  DecisionTreeRegressor(criterion='mae', max_depth=1)\n",
        "stump.fit(x_tr, y_tr)\n",
        "fin = time.time()\n",
        "print(fin - ini, \"[s]\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42.482816219329834 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt0GGhf0TgA3",
        "colab_type": "code",
        "outputId": "fefad5ed-399e-4b47-8b0d-3211d6bfc0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "score_tr_stump = stump.score(x_tr, y_tr)\n",
        "score_val_stump = stump.score(x_val, y_val)\n",
        "\n",
        "print(\"Training score: \", stump.score(x_tr, y_tr))\n",
        "print(\"Validation score: \", stump.score(x_val, y_val))\n",
        "\n",
        "predicted_tr = stump.predict(x_tr)\n",
        "predicted_val = stump.predict(x_val)\n",
        "MAE_tr_stump = mean_absolute_error(y_tr, predicted_tr)\n",
        "MAE_val_stump = mean_absolute_error(y_val, predicted_val)\n",
        "\n",
        "print(\"Training set MAE: \", MAE_tr_stump)\n",
        "print(\"Validation set MAE: \", MAE_val_stump)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score:  0.4097192095674549\n",
            "Validation score:  0.40161242512700357\n",
            "Training set MAE:  0.5823653752082486\n",
            "Validation set MAE:  0.5882200215706899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1lec44gj8ju",
        "colab_type": "text"
      },
      "source": [
        "Comparando valores, queda mejor expresado así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tNOqjXeUEju",
        "colab_type": "code",
        "outputId": "6180bfcf-3188-48b3-dbc4-077d1abc179a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print(pd.DataFrame([[\"Árbol profundidad 3\", score_tr, MAE_tr], [\"Stump\", score_tr_stump, MAE_tr_stump]], columns = [\"Tipo\", \"Score\", \"MAE\"]))\n",
        "print(pd.DataFrame([[\"Árbol profundidad 3\", score_val, MAE_val], [\"Stump\", score_val_stump, MAE_val_stump]], columns = [\"Tipo\", \"Score\", \"MAE\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Tipo     Score       MAE\n",
            "0  Árbol profundidad 3  0.671262  0.373132\n",
            "1                Stump  0.409719  0.582365\n",
            "                  Tipo     Score       MAE\n",
            "0  Árbol profundidad 3  0.668018  0.381435\n",
            "1                Stump  0.401612  0.588220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwOEyFizlHgg",
        "colab_type": "text"
      },
      "source": [
        "La primera tabla es entrenamiento y la segunda es validación. Podemos ver que el desempeño de un árbol con más profundidad es mejor, esto debido a que toma más criterios a la hora de definir el target. Al tomar un solo nodo, se intenta dualizar la decisión respecto a un solo criterio, por lo que en casos más específicos tiende a equivocarse más. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0bF4jYuli8C",
        "colab_type": "text"
      },
      "source": [
        "## e) Profundidad máxima\n",
        "\n",
        "Debido a que el valor de la profundidad influye en el desempeño del árbol, realizaremos un KFold con los conjuntos para analizar como varía el desempeño mientras cambiamos el tamaño del árbol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duoUJLbjlihH",
        "colab_type": "code",
        "outputId": "43242681-f7fe-4c0d-d554-a9e027c1dec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "depth_tree = range(1, 21)\n",
        "folds = KFold(5)\n",
        "scores = np.zeros([20, 5])\n",
        "mae = np.zeros([20, 5])\n",
        "indexes =  []\n",
        "for i in range(0, 20):\n",
        "  j = 0\n",
        "  for train_index, val_index in folds.split(x_tr):\n",
        "    N = len(val_index)\n",
        "    y_train_i = y_tr[train_index]\n",
        "    x_train_fold = x_tr[train_index]\n",
        "    y_val_i = y_tr[val_index]\n",
        "    x_val_fold = x_tr[val_index]\n",
        "    tree =  DecisionTreeRegressor(criterion='mae', max_depth = depth_tree[i])\n",
        "    model = tree.fit(x_train_fold, y_train_i)\n",
        "    scores[i][j] = model.score(x_val_fold,y_val_i)\n",
        "    y_pred = model.predict(x_val_fold)\n",
        "    mae[i][j] = np.sum([abs(y_pred[k] - y_val_i[k]) for k in range(N-1)])/N\n",
        "    j+=1\n",
        "    indexes.append((j, depth_tree[i]))\n",
        "  print(\"Depth: \", depth_tree[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Depth:  1\n",
            "Depth:  2\n",
            "Depth:  3\n",
            "Depth:  4\n",
            "Depth:  5\n",
            "Depth:  6\n",
            "Depth:  7\n",
            "Depth:  8\n",
            "Depth:  9\n",
            "Depth:  10\n",
            "Depth:  11\n",
            "Depth:  12\n",
            "Depth:  13\n",
            "Depth:  14\n",
            "Depth:  15\n",
            "Depth:  16\n",
            "Depth:  17\n",
            "Depth:  18\n",
            "Depth:  19\n",
            "Depth:  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TarOXI2RkyjO",
        "colab_type": "code",
        "outputId": "c87012ba-3424-4a2f-da39-362285b2b9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0, 20):\n",
        "  print(\"Depth: \", i + 1)\n",
        "  print(\"    Average Validation Score: \", np.sum(scores[i]) / 5)\n",
        "  print(\"    Average Validation MAE: \", np.sum(mae[i]) / 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Depth:  1\n",
            "    Average Validation Score:  0.40703998684098674\n",
            "    Average Validation MAE:  1.7497686282878049\n",
            "Depth:  2\n",
            "    Average Validation Score:  0.5710718646588967\n",
            "    Average Validation MAE:  1.3795969951580758\n",
            "Depth:  3\n",
            "    Average Validation Score:  0.6701746197756391\n",
            "    Average Validation MAE:  1.11888491861694\n",
            "Depth:  4\n",
            "    Average Validation Score:  0.7742793480296013\n",
            "    Average Validation MAE:  0.873211987378923\n",
            "Depth:  5\n",
            "    Average Validation Score:  0.8389704089811321\n",
            "    Average Validation MAE:  0.6654319509781759\n",
            "Depth:  6\n",
            "    Average Validation Score:  0.8947023702457425\n",
            "    Average Validation MAE:  0.501087226914824\n",
            "Depth:  7\n",
            "    Average Validation Score:  0.9339391902600074\n",
            "    Average Validation MAE:  0.36564722074138634\n",
            "Depth:  8\n",
            "    Average Validation Score:  0.9544865756002643\n",
            "    Average Validation MAE:  0.2741450704326135\n",
            "Depth:  9\n",
            "    Average Validation Score:  0.9673924237235347\n",
            "    Average Validation MAE:  0.2090677832394051\n",
            "Depth:  10\n",
            "    Average Validation Score:  0.9757542900910652\n",
            "    Average Validation MAE:  0.1599003934655207\n",
            "Depth:  11\n",
            "    Average Validation Score:  0.9807125454494579\n",
            "    Average Validation MAE:  0.12429947308585956\n",
            "Depth:  12\n",
            "    Average Validation Score:  0.9832261706208316\n",
            "    Average Validation MAE:  0.10210459089768628\n",
            "Depth:  13\n",
            "    Average Validation Score:  0.984552891359888\n",
            "    Average Validation MAE:  0.08831885062398608\n",
            "Depth:  14\n",
            "    Average Validation Score:  0.9847909478070825\n",
            "    Average Validation MAE:  0.07988737561677314\n",
            "Depth:  15\n",
            "    Average Validation Score:  0.984386393103185\n",
            "    Average Validation MAE:  0.07530458086049646\n",
            "Depth:  16\n",
            "    Average Validation Score:  0.9859169711871767\n",
            "    Average Validation MAE:  0.06893675780345077\n",
            "Depth:  17\n",
            "    Average Validation Score:  0.9857626273214681\n",
            "    Average Validation MAE:  0.0673368507876187\n",
            "Depth:  18\n",
            "    Average Validation Score:  0.9856157051947638\n",
            "    Average Validation MAE:  0.06612483589544993\n",
            "Depth:  19\n",
            "    Average Validation Score:  0.9856495636694849\n",
            "    Average Validation MAE:  0.06508275834807248\n",
            "Depth:  20\n",
            "    Average Validation Score:  0.9856379216419529\n",
            "    Average Validation MAE:  0.06501565040663224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK0nDSOlpnVw",
        "colab_type": "text"
      },
      "source": [
        "Podemos apreciar que mientras más aumenta la cantidad de hoja, el score del modelo va aumentando considerablemente. Esto claramente puede provocar overfitting, ya que si tenemos una gran cantidad de aciertos en un conjunto significa que está aprendiendo los patrones específicos de ese conjunto.\n",
        "\n",
        "## f) Random Forest\n",
        "\n",
        "Como se vió anteriormente, un árbol con mucha profundidad puede provocar overfitting y es algo inevitable, por lo que siempre se busca un nivel de profundidad donde podemos tener un mejor desempeño o, lo que se busca, generalización. \n",
        "\n",
        "Aparte de eso, podemos aplicar otro modelo llamado Random Forest, el cual genera una cantidad fija de árboles los cuales aprenden de partes parciales del conjunto de entrenamiento. Con esto en mente, cada árbol aprendió de partes distintas, por lo que tendrán una noción del espacio distinto. Esto implica a que dentro de diversas predicciones de nuevos datos, los árboles se desempeñaran de diversas formas, y la falencia que tenga en la predicción un árbol la puede complementar otro. Esto también se denomina un ensamble o un consenso entre los árboles, donde el modelo devuelve el valor del árbol con mejor desempeño.\n",
        "\n",
        "Para probar esto, entrenaremos un modelo de Random Forest con una profundidad de 5, debido a que es un valor que en el KFold anterior era bastante bueno pero no tan cercano para definirlo como overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFHKsA9hAOtv",
        "colab_type": "code",
        "outputId": "9e0d2057-b94a-453d-ddfc-9ad35a0ba87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "ini = time.time()\n",
        "forest = RandomForestRegressor(n_estimators=20, criterion='mae', max_depth=5)\n",
        "forest.fit(x_tr, y_tr)\n",
        "fin = time.time()\n",
        "print(fin - ini, \"[s]\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "964.1379325389862 [s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwXKtSEL1Tn1",
        "colab_type": "code",
        "outputId": "fe7ea78e-796e-4065-e904-cb33516ac354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "score_tr_forest = forest.score(x_tr, y_tr)\n",
        "score_val_forest = forest.score(x_val, y_val)\n",
        "\n",
        "print(\"Training score: \", forest.score(x_tr, y_tr))\n",
        "print(\"Validation score: \", forest.score(x_val, y_val))\n",
        "\n",
        "predicted_tr_forest = forest.predict(x_tr)\n",
        "predicted_val_forest = forest.predict(x_val)\n",
        "MAE_tr_forest = mean_absolute_error(y_tr, predicted_tr_forest)\n",
        "MAE_val_forest = mean_absolute_error(y_val, predicted_val_forest)\n",
        "\n",
        "print(\"Training set MAE: \", MAE_tr_forest)\n",
        "print(\"Validation set MAE: \", MAE_val_forest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score:  0.8862274438695785\n",
            "Validation score:  0.8894580319131108\n",
            "Training set MAE:  0.21814603081047532\n",
            "Validation set MAE:  0.2197568607296838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42xhaNIV2A-k",
        "colab_type": "text"
      },
      "source": [
        "Podemos apreciar que el desempeño es bastante bueno, además no tiene una noción de overfitting comparado con árboles más profundos. Incluso, el desempeño de ambos conjuntos (entrenamiento y validación) poseen el mismo desempeño. Esto claramente porque con Random Forest se logra generalizar más el problema comparado a un árbol por sí solo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiHoIv6zk7s",
        "colab_type": "text"
      },
      "source": [
        "## g) Otros parámetros\n",
        "\n",
        "Por último, investigaremos más sobre los parámetros que tiene el árbol de decisión y como afectan en su desempeño, para poder buscar una forma de mejorar el desempeño.\n",
        "\n",
        "\n",
        "\n",
        "*   Criterion: El criterio con el cual se calculará la función de pérdida, teniendo mse, mae y friedman_mse.\n",
        "*   Splitter: La estrategia usada para decidir la partición en cada nodo, teniendo el criterio \"best\" para el mejor o \"random\".\n",
        "*   max_depth: Es la máxima profundidad que el algoritmo buscará generar en el árbol\n",
        "*   min_samples_split: Es la mínima cantidad de muestras en las cual se decidirá si se divide o no un nodo.\n",
        "*   min_samples_leaf:\n",
        "*   min_weight_fraction_leaf: \n",
        "*   max_features: El número de atributos que serán considerados para buscar la mejor división.\n",
        "*   random_state: Es la semilla que genera números aleatorios. Si no se indica, se usa la semilla otorgada por numpy\n",
        "*   max_leaf_nodes: \n",
        "*   min_impurity_decrease: El nodo se dividirá si, al hacer la división, la impureza es igual o menor a la actual (valor otorgado por este parámetro.)\n",
        "*   min_impurity_split: Este valor actúa como umbral, donde un nodo se dividirá si supera este umbral o será una hoja en caso contrario.\n",
        "*   presort: Variable booleana que reordena los datos de entrada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4SPu9L2FSUh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2z8naD1xVOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}